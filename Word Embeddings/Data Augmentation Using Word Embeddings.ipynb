{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation Using Word Embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "93nOAMLOe6_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "kkhN5vXJgLN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "zAGXYqxLgGVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Google News Vectors"
      ],
      "metadata": {
        "id": "m6ztl7jugHQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P /root/vectors/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "qYZ09121e4CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_NEWS_VECTORS = '/root/vectors/GoogleNews-vectors-negative300.bin.gz'\n",
        "word2vec = KeyedVectors.load_word2vec_format(GOOGLE_NEWS_VECTORS, binary=True)\n",
        "print(\"Vectors loaded successfully: \"+str(len(word2vec.vocab)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Ym8M2wjkf2_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectors"
      ],
      "metadata": {
        "id": "ZFmdRGqYqRkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Sentences:\n",
        "\n",
        "*   `Winter` is coming.\n",
        "*   Any `man` who must say \"I am the `king`\" is no true `king`.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dtYvQpMbq-mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = [[\"winter\"], [\"man\"], [\"king\"]]\n",
        "\n",
        "for w in keywords:\n",
        "  word = w[0]\n",
        "  print(\"Word: \"+word)\n",
        "  vector = word2vec.get_vector(word)\n",
        "  print(\"Vector length: {}\".format(len(vector)))\n",
        "  print(vector)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "dfGxMs9CsZof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine Similarity\n",
        "\n"
      ],
      "metadata": {
        "id": "hvn4RpfEin7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consine Similarity formula: \n",
        "\n",
        "$\\text{cos}(a,b) = \\frac{a \\cdot b}{||a|| \\cdot  ||b||}$"
      ],
      "metadata": {
        "id": "XUQDRn3Ah49h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(x1, x2):\n",
        "  return np.round(np.dot(x1, x2)/(np.linalg.norm(x1)*np.linalg.norm(x2)),5)\n",
        "print(cosine_similarity(word2vec.get_vector(\"winter\"), word2vec.get_vector(\"summer\")))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "JMqYExDNhqsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec.similarity(\"winter\",\"summer\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "YRVv4mf6hLjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similar Words"
      ],
      "metadata": {
        "id": "Sx3LPs2FI6mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for w in keywords:\n",
        "  print(word2vec.most_similar(positive=w, topn = 10))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "eLAVZuBfgaYh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4o3WD5SNSmCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   [Efficient estimation of word representations in vector space](https://arxiv.org/pdf/1301.3781.pdf) \n",
        "*   [Word embeddings](https://https://en.wikipedia.org/wiki/Word_embedding) \n",
        "*   [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
        "*   [Gensim](https://github.com/RaRe-Technologies/gensim) "
      ],
      "metadata": {
        "id": "A3CYp8kOVzzA"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Data Augmentation Using Word Embeddings",
      "provenance": [],
      "collapsed_sections": [
        "ZFmdRGqYqRkA",
        "hvn4RpfEin7s"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}